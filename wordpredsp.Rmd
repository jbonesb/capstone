---
title: "Next word prediction"
author: "Bogdanov Sergey"
date: '25.06.2019'
output: ioslides_presentation
runtime: shiny
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(stringr)
library(dplyr)
library(tidytext)
library(plyr)
library(data.table)
```
```{r, echo = FALSE, cache = TRUE}
load("stat.Rdata")
load("txt.RData")
```

## Task Description

This paper describes the development of a language model that should predict the expected next word for the user who will type some sentence.  

To train the model [text corpus](https://d396qusza40orc.cloudfront.net/dsscapstone/dataset/Coursera-SwiftKey.zip) of more than 4,2 mln sentences from blogs, news and tweets were used.

A research analysis was performed as a preparatory step to the development of the model. It's described [here](http://rpubs.com/jbone/499816) in details.



## Predictive model

The [n-gram](https://en.wikipedia.org/wiki/N-gram) approach was used to create language model.
The final model uses trigrams and bigrams to predict the next word. 

To improve the accuracy of the model an interpolation method known as [Kneser-Nei Smoothing](https://www.google.com/search?rlz=1C1SQJL_ruRU829RU829&ei=mRwTXdbnBvGorgSPn6f4CQ&q=Kneser+Ney+smoothing+wikipedia) was used. This method helps smooth the probability of n-grams from direct counts using information about how likely next word appears as a novel continuation.   

To minimize memory usage for storing n-gram dictionaries  

- only the 3 most likely outcomes for trigrams and bigrams are used,
- words are encoded with integers in the dictionaries.

You can find R code of model development and performance assessment on [github](https://github.com/jbonesb/capstone).


## Model performance

To assess model accuracy "out of sample" approach was used. Initial sentence array was splitted on train and test datasets. Then the train dataset was used to train the model and test dataset was used for accuracy assement.

Accuracy of final model is presented in the table below
```{r stat}
report[,1:3]
```

The model needs around **330 Mb** of memory to store n-gram dictionaries.


## One picture is worth a thousand words
You need just start typing text and put whitespace or click word on the button and you will see three best next word prediction on the buttons.
```{r, echo=FALSE}
shinyApp(

ui = fluidPage(
    
    # titlePanel("Next word prediction"),
    
    sidebarLayout(
        sidebarPanel(
            
            p("This is an application that predict next best word based on n-grams and use several backoff models and interpolation."),
            
            br(),
            p("Just start typing, then press whitespace and see how it works."),
            
            # br(),  
            # p("Model and application development description you can find", 
            #   a(href="http://rpubs.com/jbone/499816", "here"), "."),
            
            br()
        ),
        
        mainPanel(
            textAreaInput("strInput","Please, start typing", width = "150%", rows = 3),
            br(),

            actionButton("ab1", textOutput("tab1"), width = "30%"),
            actionButton("ab2", textOutput("tab2"), width = "30%"),
            actionButton("ab3", textOutput("tab3"), width = "30%"),
 
        br()
        )
    )
),

 server = function(input, output, session) {
    rv <- reactiveValues(pw1 = UD$word[1], pw2 = UD$word[2], pw3 = UD$word[3])

    observeEvent(input$ab1, {
        updateTextInput(session, "strInput", value =  paste(str_squish(input$strInput), rv$pw1, "" ) )
    })
    observeEvent(input$ab2, {
        updateTextInput(session, "strInput", value =  paste(str_squish(input$strInput), rv$pw2, "" ) )
    })
    observeEvent(input$ab3, {
        updateTextInput(session, "strInput", value =  paste(str_squish(input$strInput), rv$pw3, "" ) )
    })
    output$tab1 <- renderText({
        pwords()[1]
    })
    output$tab2 <- renderText({
        pwords()[2]
    })
    output$tab3 <- renderText({
        pwords()[3]
    })    
    
    pwords <- reactive({
        if (grepl(" $", input$strInput)) {
            t <- NULL
            words <- tibble(text= input$strInput) %>% unnest_tokens(word, text)

            if (nrow(words) == 1) {
 
                t <- UD[BDc[wc1 == UD[word == words$word[1],]$wc[1], ], on="wc==wc2"]
                    
                if (nrow(t) > 0) rv$pw1 = t$word[1]
                if (nrow(t) > 1) rv$pw2 = t$word[2]
                if (nrow(t) > 2) rv$pw3 = t$word[3]
            } 
            
            if (nrow(words) >= 2) {
                l = nrow(words)

                t <- UD[TDc[wc1 == UD[word == words$word[l-1],]$wc[1] &
                            wc2 == UD[word == words$word[l],]$wc[1], ], on="wc==wc3"]
                
                if (nrow(t) < 3) {
                    if (nrow(t) == 0){
                        t <- UD[BDc[wc1 == UD[word == words$word[l],]$wc[1], ], on="wc==wc2"]
                    }else{
                        t <- rbind.fill(t, UD[BDc[wc1 == UD[word == words$word[l],]$wc[1], ], on="wc==wc2"])
                    }
                }
                
                if (nrow(t) > 0) rv$pw1 = t$word[1]
                if (nrow(t) > 1) rv$pw2 = t$word[2]
                if (nrow(t) > 2) rv$pw3 = t$word[3] 
            } 
        }
        print(memory.size())
        gc()
        
        c(rv$pw1, rv$pw2, rv$pw3)
    })
  },

  options = list(height = 500)
)
# inputPanel(
#   selectInput("n_breaks", label = "Number of bins:",
#               choices = c(10, 20, 35, 50), selected = 20),
#   
#   sliderInput("bw_adjust", label = "Bandwidth adjustment:",
#               min = 0.2, max = 2, value = 1, step = 0.2)
# )
# 
# renderPlot({
#   hist(faithful$eruptions, probability = TRUE, breaks = as.numeric(input$n_breaks),
#        xlab = "Duration (minutes)", main = "Geyser eruption duration")
#   
#   dens <- density(faithful$eruptions, adjust = input$bw_adjust)
#   lines(dens, col = "blue")
# })
```




